{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project #\n",
    "\n",
    "## Terrance West ##\n",
    "**Please use this template to fill in your code and comments (* you can modify for your project need *) ** \n",
    "\n",
    "\n",
    "**Add your readme here** if you have any special configuration or steps needed to follow to run your code \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "#more packages import as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SP500</th>\n",
       "      <th>NASDAQ.AAL</th>\n",
       "      <th>NASDAQ.AAPL</th>\n",
       "      <th>NASDAQ.ADBE</th>\n",
       "      <th>NASDAQ.ADI</th>\n",
       "      <th>NASDAQ.ADP</th>\n",
       "      <th>NASDAQ.ADSK</th>\n",
       "      <th>NASDAQ.AKAM</th>\n",
       "      <th>NASDAQ.ALXN</th>\n",
       "      <th>...</th>\n",
       "      <th>NYSE.WYN</th>\n",
       "      <th>NYSE.XEC</th>\n",
       "      <th>NYSE.XEL</th>\n",
       "      <th>NYSE.XL</th>\n",
       "      <th>NYSE.XOM</th>\n",
       "      <th>NYSE.XRX</th>\n",
       "      <th>NYSE.XYL</th>\n",
       "      <th>NYSE.YUM</th>\n",
       "      <th>NYSE.ZBH</th>\n",
       "      <th>NYSE.ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41261</th>\n",
       "      <td>1504209360</td>\n",
       "      <td>2472.22</td>\n",
       "      <td>44.72</td>\n",
       "      <td>164.11</td>\n",
       "      <td>155.090</td>\n",
       "      <td>83.67</td>\n",
       "      <td>106.565</td>\n",
       "      <td>114.49</td>\n",
       "      <td>47.150</td>\n",
       "      <td>142.425</td>\n",
       "      <td>...</td>\n",
       "      <td>99.675</td>\n",
       "      <td>99.53</td>\n",
       "      <td>49.485</td>\n",
       "      <td>40.955</td>\n",
       "      <td>76.360</td>\n",
       "      <td>32.285</td>\n",
       "      <td>62.110</td>\n",
       "      <td>76.88</td>\n",
       "      <td>114.31</td>\n",
       "      <td>62.7250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41262</th>\n",
       "      <td>1504209420</td>\n",
       "      <td>2471.77</td>\n",
       "      <td>44.73</td>\n",
       "      <td>164.12</td>\n",
       "      <td>155.160</td>\n",
       "      <td>83.65</td>\n",
       "      <td>106.590</td>\n",
       "      <td>114.52</td>\n",
       "      <td>47.150</td>\n",
       "      <td>142.450</td>\n",
       "      <td>...</td>\n",
       "      <td>99.730</td>\n",
       "      <td>99.63</td>\n",
       "      <td>49.480</td>\n",
       "      <td>40.960</td>\n",
       "      <td>76.370</td>\n",
       "      <td>32.295</td>\n",
       "      <td>62.100</td>\n",
       "      <td>76.90</td>\n",
       "      <td>114.33</td>\n",
       "      <td>62.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41263</th>\n",
       "      <td>1504209480</td>\n",
       "      <td>2470.03</td>\n",
       "      <td>44.74</td>\n",
       "      <td>164.01</td>\n",
       "      <td>155.065</td>\n",
       "      <td>83.62</td>\n",
       "      <td>106.520</td>\n",
       "      <td>114.47</td>\n",
       "      <td>47.150</td>\n",
       "      <td>142.330</td>\n",
       "      <td>...</td>\n",
       "      <td>99.735</td>\n",
       "      <td>99.64</td>\n",
       "      <td>49.495</td>\n",
       "      <td>40.940</td>\n",
       "      <td>76.315</td>\n",
       "      <td>32.290</td>\n",
       "      <td>62.090</td>\n",
       "      <td>76.88</td>\n",
       "      <td>114.31</td>\n",
       "      <td>62.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41264</th>\n",
       "      <td>1504209540</td>\n",
       "      <td>2471.49</td>\n",
       "      <td>44.71</td>\n",
       "      <td>163.88</td>\n",
       "      <td>154.960</td>\n",
       "      <td>83.58</td>\n",
       "      <td>106.400</td>\n",
       "      <td>114.33</td>\n",
       "      <td>47.135</td>\n",
       "      <td>142.170</td>\n",
       "      <td>...</td>\n",
       "      <td>99.700</td>\n",
       "      <td>99.63</td>\n",
       "      <td>49.485</td>\n",
       "      <td>40.925</td>\n",
       "      <td>76.300</td>\n",
       "      <td>32.275</td>\n",
       "      <td>62.075</td>\n",
       "      <td>76.83</td>\n",
       "      <td>114.23</td>\n",
       "      <td>62.6301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41265</th>\n",
       "      <td>1504209600</td>\n",
       "      <td>2471.49</td>\n",
       "      <td>44.74</td>\n",
       "      <td>163.98</td>\n",
       "      <td>155.160</td>\n",
       "      <td>83.69</td>\n",
       "      <td>106.470</td>\n",
       "      <td>114.46</td>\n",
       "      <td>47.150</td>\n",
       "      <td>142.410</td>\n",
       "      <td>...</td>\n",
       "      <td>99.670</td>\n",
       "      <td>99.64</td>\n",
       "      <td>49.490</td>\n",
       "      <td>40.940</td>\n",
       "      <td>76.320</td>\n",
       "      <td>32.270</td>\n",
       "      <td>62.070</td>\n",
       "      <td>76.81</td>\n",
       "      <td>114.28</td>\n",
       "      <td>62.6800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE    SP500  NASDAQ.AAL  NASDAQ.AAPL  NASDAQ.ADBE  NASDAQ.ADI  \\\n",
       "41261  1504209360  2472.22       44.72       164.11      155.090       83.67   \n",
       "41262  1504209420  2471.77       44.73       164.12      155.160       83.65   \n",
       "41263  1504209480  2470.03       44.74       164.01      155.065       83.62   \n",
       "41264  1504209540  2471.49       44.71       163.88      154.960       83.58   \n",
       "41265  1504209600  2471.49       44.74       163.98      155.160       83.69   \n",
       "\n",
       "       NASDAQ.ADP  NASDAQ.ADSK  NASDAQ.AKAM  NASDAQ.ALXN    ...     NYSE.WYN  \\\n",
       "41261     106.565       114.49       47.150      142.425    ...       99.675   \n",
       "41262     106.590       114.52       47.150      142.450    ...       99.730   \n",
       "41263     106.520       114.47       47.150      142.330    ...       99.735   \n",
       "41264     106.400       114.33       47.135      142.170    ...       99.700   \n",
       "41265     106.470       114.46       47.150      142.410    ...       99.670   \n",
       "\n",
       "       NYSE.XEC  NYSE.XEL  NYSE.XL  NYSE.XOM  NYSE.XRX  NYSE.XYL  NYSE.YUM  \\\n",
       "41261     99.53    49.485   40.955    76.360    32.285    62.110     76.88   \n",
       "41262     99.63    49.480   40.960    76.370    32.295    62.100     76.90   \n",
       "41263     99.64    49.495   40.940    76.315    32.290    62.090     76.88   \n",
       "41264     99.63    49.485   40.925    76.300    32.275    62.075     76.83   \n",
       "41265     99.64    49.490   40.940    76.320    32.270    62.070     76.81   \n",
       "\n",
       "       NYSE.ZBH  NYSE.ZTS  \n",
       "41261    114.31   62.7250  \n",
       "41262    114.33   62.7100  \n",
       "41263    114.31   62.6850  \n",
       "41264    114.23   62.6301  \n",
       "41265    114.28   62.6800  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in your data into a dataframe like df = pd.read_csv(\"yourfile.csv\")\n",
    "df = pd.read_csv(\"/Users/Twest94/Documents/DS 5K/data_stocks.csv\")\n",
    "#df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Describe the basic format of the data and the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE             int64\n",
       "SP500          float64\n",
       "NASDAQ.AAL     float64\n",
       "NASDAQ.AAPL    float64\n",
       "NASDAQ.ADBE    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41266 entries, 0 to 41265\n",
      "Columns: 502 entries, DATE to NYSE.ZTS\n",
      "dtypes: float64(501), int64(1)\n",
      "memory usage: 158.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41266, 502)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'SP500', 'NASDAQ.AAL', 'NASDAQ.AAPL', 'NASDAQ.ADBE',\n",
       "       'NASDAQ.ADI', 'NASDAQ.ADP', 'NASDAQ.ADSK', 'NASDAQ.AKAM', 'NASDAQ.ALXN',\n",
       "       ...\n",
       "       'NYSE.WYN', 'NYSE.XEC', 'NYSE.XEL', 'NYSE.XL', 'NYSE.XOM', 'NYSE.XRX',\n",
       "       'NYSE.XYL', 'NYSE.YUM', 'NYSE.ZBH', 'NYSE.ZTS'],\n",
       "      dtype='object', length=502)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the original column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='describe'></a>\n",
    "\n",
    "###  Summary statistics for the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "# df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Tensorflow #\n",
    "Prepping data by dropping the 'DATE' variable, defining dimensions of data set in order to set train/test split, and \n",
    "converting data into an numpy array, which is what tensorflow requires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date variable\n",
    "data = df.drop(['DATE'], 1)\n",
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]\n",
    "# Make data a numpy array\n",
    "data = data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20674266"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for training/test data as well as establishing the 70/30, train (70) and test (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.7*n))\n",
    "test_start = train_end\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MinMaxScaler() without specification defaults to range 0 to 1; this is more robust to standard deviations to outliers. This may not be revelant for the timeframe of data her, but in volatile market, it could help models deal with the effects of the high variance better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = all minutes of data from 1 to end \n",
    "y_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14471886"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14443000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6202380"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders # \n",
    "\n",
    "It all starts with placeholders. We need two placeholders in order to fit our model - X contains the network's inputs (the stock prices of all S&P 500 constituents at time T = t) and Y the network's outputs (the index value of the S&P 500 at time T = t + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 500])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the neural network #\n",
    "\n",
    "After having defined the placeholders, variables, initializers, cost functions and optimizers of the network, the model needs to be trained. Usually, this is done by minibatch training. During minibatch training random data samples of n = batch_size are drawn from the training data and fed into the network. The training dataset gets divided into n / batch_size batches that are sequentially fed into the network. At this point the placeholders X and Y come into play. They store the input and target data and present them to the network as inputs and targets.\n",
    "\n",
    "A sampled data batch of X flows through the network until it reaches the output layer. There, TensorFlow compares the models predictions against the actual observed targets Y in the current batch. Afterwards, TensorFlow conducts an optimization step and updates the networks parameters, corresponding to the selected learning scheme. After having updated the weights and biases, the next batch is sampled and the process repeats itself. The procedure continues until all batches have been presented to the network. One full sweep over all batches is called an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture parameters #\n",
    "\n",
    "The model consists of four hidden layers. The first layer contains 1000 neurons, double the size of the inputs. Subsequent hidden layers are always half the size of the previous layer, which means 500, 250, and 125 neurons. A reduction of the number of neurons for each subsequent layer compresses the information the network identifies in the previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks = 500\n",
    "n_neurons_1 = 1000\n",
    "n_neurons_2 = 500\n",
    "n_neurons_3 = 250\n",
    "n_neurons_4 = 125\n",
    "n_target = 1\n",
    "# Layer 1: Variables for hidden weights and biases\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "# Layer 2: Variables for hidden weights and biases\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "# Layer 3: Variables for hidden weights and biases\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "# Layer 4: Variables for hidden weights and biases\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output layer: Variables for output weights and biases\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))\n",
    "bias_out = tf.Variable(bias_initializer([n_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (must be transposed)\n",
    "# Output layer multiplies the weights by output and adds the bias \n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function #\n",
    "\n",
    "The cost function of the network is used to generate a measure of deviation between the networkâ€™s predictions and the actual observed training targets. For regression problems, the mean squared error (MSE) function is commonly used. MSE computes the average squared deviation between predictions and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer #\n",
    "the Adam (adaptive moment estimator) optimizer function is more straightfoward and computationally efficient that usual stochastic gradient decent. It's one of the defaults in deep learning development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the neural network #\n",
    "\n",
    "After having defined the placeholders, variables, initializers, cost functions and optimizers of the network, the model needs to be trained. Usually, this is done by minibatch training. During minibatch training random data samples of n = batch_size are drawn from the training data and fed into the network. The training dataset gets divided into - n / batch_size - batches that are sequentially fed into the network. At this point the placeholders X and Y come into play. They store the input and target data and present them to the network as inputs and targets.\n",
    "\n",
    "A sampled data batch of X flows through the network until it reaches the output layer. There, TensorFlow compares the models predictions against the actual observed targets Y in the current batch. Afterwards, TensorFlow conducts an optimization step and updates the networks parameters, corresponding to the selected learning scheme. After having updated the weights and biases, the next batch is sampled and the process repeats itself. The procedure continues until all batches have been presented to the network. One full sweep over all batches is called an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Session A Session object encapsulates the environment in which Operation \n",
    "# objects are executed, and Tensor objects are evaluated\n",
    "net = tf.Session()\n",
    "# Run initializer\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# Number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 250\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        # iterates through training data in increments of batch size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Runs optimizer with each batch and minizes the mse between training input X, and the expected output Y\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "        # Prediction\n",
    "        pred = net.run(out, feed_dict={X: X_test})\n",
    "                       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99983335 1.0010439  1.0009141  ... 0.95750904 0.9489861  0.95545685]]\n"
     ]
    }
   ],
   "source": [
    "best = net.run(out,feed_dict={X: X_test})\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose:0' shape=(1, ?) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected dimension in the range [-1, 1), but got 1\n\t [[Node: ArgMax_17 = ArgMax[T=DT_DOUBLE, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_17/input, ArgMax_17/dimension)]]\n\nCaused by op 'ArgMax_17', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-8969f3feaa91>\", line 1, in <module>\n    correct_prediction = tf.equal(tf.argmax(pred, 1),tf.argmax(y_train, 1))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 220, in argmax\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 783, in arg_max\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Expected dimension in the range [-1, 1), but got 1\n\t [[Node: ArgMax_17 = ArgMax[T=DT_DOUBLE, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_17/input, ArgMax_17/dimension)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [-1, 1), but got 1\n\t [[Node: ArgMax_17 = ArgMax[T=DT_DOUBLE, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_17/input, ArgMax_17/dimension)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8969f3feaa91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [-1, 1), but got 1\n\t [[Node: ArgMax_17 = ArgMax[T=DT_DOUBLE, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_17/input, ArgMax_17/dimension)]]\n\nCaused by op 'ArgMax_17', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-8969f3feaa91>\", line 1, in <module>\n    correct_prediction = tf.equal(tf.argmax(pred, 1),tf.argmax(y_train, 1))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 220, in argmax\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 783, in arg_max\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Expected dimension in the range [-1, 1), but got 1\n\t [[Node: ArgMax_17 = ArgMax[T=DT_DOUBLE, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax_17/input, ArgMax_17/dimension)]]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred, 1),tf.argmax(y_train, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "net.run(accuracy, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result # \n",
    "\n",
    "Final MSE after training the model, for 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033336051\n"
     ]
    }
   ],
   "source": [
    "mse_final = net.run(mse, feed_dict={X: X_test, Y: y_test})\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9914709 , 0.99286693, 0.9929429 , ..., 0.9399659 , 0.93226814,\n",
       "        0.9381017 ]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# line1, = ax1.plot(y_test)\n",
    "# line2, = ax1.plot(pred)\n",
    "# line2.set_ydata(pred)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
